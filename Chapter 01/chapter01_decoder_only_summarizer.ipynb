{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63c5d99",
   "metadata": {},
   "source": [
    "# Decoder only Summarizer\n",
    "\n",
    "Example of using a decoder-only language model from Hugging Face's Transformers library for text summarization in PyTorch. We'll be using the BartForConditionalGeneration model, which is a pre-trained sequence-to-sequence model based on the BART (Bidirectional and Auto-Regressive Transformers) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c79b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773a87f",
   "metadata": {},
   "source": [
    "We import the required modules from the Transformers library: BartForConditionalGeneration (the pre-trained model) and BartTokenizer (for tokenizing the input text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5ce480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64ae88",
   "metadata": {},
   "source": [
    "We load the pre-trained bart-large-cnn model and tokenizer using the from_pretrained method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9091ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93afc5731d5b4a49b0115f5761bc8ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc32c2bcde2a41e1b9083dd92340d84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8258a97aaa24c438d7dd2afda102513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4422c8af64a4472bc01d9bb28d57c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a0fcf7b0e44342a26811ce8492d903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a9e412576b48a1bafa0bc0c58d6c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c52b3",
   "metadata": {},
   "source": [
    "We move the model to the GPU if available, using PyTorch's device functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28df20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b224835",
   "metadata": {},
   "source": [
    "Example article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544a1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example article to summarize\n",
    "article = \"\"\"\n",
    "The Astonishing Hypothesis is a 1994 book by scientist Francis Crick about consciousness and neuroscience. In it, Crick promotes the idea that consciousness is produced by physical and chemical processes in the brain, and that neuroscience will eventually have a theory which can explain consciousness. The book surveys the history of research into consciousness and outlines several hypotheses about the neural correlates of various components and properties of consciousness.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c684f",
   "metadata": {},
   "source": [
    "We tokenize the article using the tokenizer, specifying that we want the output as PyTorch tensors (return_tensors=\"pt\"). \n",
    "\n",
    "We also set max_length=1024 to truncate the input if it exceeds that length, and truncation=True to allow truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88eb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the article\n",
    "inputs = tokenizer(article, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "input_ids = inputs.input_ids.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9af5fa",
   "metadata": {},
   "source": [
    "We call the generate method of the model with the tokenized input. \n",
    "\n",
    "We specify num_beams=4 to use beam search with 4 beams, max_length=100 to limit the summary length to 100 tokens, and early_stopping=True to stop generating once the model produces the end-of-sequence token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848f0c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Generate the summary\n",
    "summary_ids = model.generate(input_ids, num_beams=4, max_length=100, early_stopping=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6601ac",
   "metadata": {},
   "source": [
    "The generate method returns a tensor of token IDs representing the generated summary. We use the tokenizer.decode method to convert the token IDs back into text, passing skip_special_tokens=True to exclude any special tokens (e.g., start/end-of-sequence tokens) from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a99cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe287420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The Astonishing Hypothesis is a 1994 book by scientist Francis Crick about consciousness and neuroscience. In it, Crick promotes the idea that consciousness is produced by physical and chemical processes in the brain, and that neuroscience will eventually have a theory which can explain consciousness.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd972b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
