{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbea7999",
   "metadata": {},
   "source": [
    "# Generate summary from articles\n",
    "This notebook demonstrates how easy it is to leverage pre-trained models from the Hugging Face Transformers library for tasks like summarization, without having to train the model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d010b2",
   "metadata": {},
   "source": [
    "We use the !pip install transformers command to install the Transformers library, which provides access to pre-trained models and utilities for various NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfd2dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ec52c",
   "metadata": {},
   "source": [
    "This step is necessary to access the pre-trained models hosted on the Hugging Face Hub. The notebook_login() function will prompt you to enter your Hugging Face token or create a new account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4430dce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a40d5ee0b94c40a575fa5d2f4c3f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authenticate with Hugging Face Hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00b960",
   "metadata": {},
   "source": [
    "We import the necessary classes from the Transformers library, specifically BartForConditionalGeneration (the pre-trained summarization model) and BartTokenizer (for tokenizing the input text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c4476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba40b92",
   "metadata": {},
   "source": [
    "We load the pre-trained bart-large-cnn model and tokenizer using the from_pretrained method, specifying the model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc46af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3f69733616475282c738dc9235730a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fa58d02ca34292ba1caa20c1cbdb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8898a4cb3264b02aff4282ef12a879b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15ccc53715d4a6b82b9d1027f7361b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a493ada62345babb1a04706c1df14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914073296df244cf84f37ed701ddb888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85329565",
   "metadata": {},
   "source": [
    "We provide an example article. You may use other articles to test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81db7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example article to summarize\n",
    "article = \"\"\"\n",
    "The Astonishing Hypothesis is a 1994 book by scientist Francis Crick about consciousness and neuroscience. In it, Crick promotes the idea that consciousness is produced by physical and chemical processes in the brain, and that neuroscience will eventually have a theory which can explain consciousness. The book surveys the history of research into consciousness and outlines several hypotheses about the neural correlates of various components and properties of consciousness.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188cded",
   "metadata": {},
   "source": [
    "We use the tokenizer to tokenize the article text, passing the return_tensors=\"pt\" argument to get the tokenized output as a PyTorch tensor. \n",
    "\n",
    "We also set max_length=1024 to truncate the input if it exceeds that length, and truncation=True to allow truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee69eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the article\n",
    "inputs = tokenizer(article, return_tensors=\"pt\", max_length=1024, truncation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708bfc1",
   "metadata": {},
   "source": [
    "\n",
    "When we call the generate method of the pre-trained summarization model, we're asking the model to take the tokenized input (the article text) and generate a summarized output sequence (the summary text).\n",
    "We pass several arguments to the generate method to control the behavior of the text generation process:\n",
    "\n",
    "- num_beams=4:\n",
    "\n",
    "This argument specifies that we want to use beam search for generating the output sequence.\n",
    "Beam search is a technique used in sequence generation tasks, where the model keeps track of the k most probable sequences at each step, instead of just the single most probable sequence.\n",
    "In this case, we set num_beams=4, which means the model will consider the 4 most probable sequences at each step when generating the summary.\n",
    "This helps the model explore more diverse and potentially better summaries, rather than just sticking to the single most likely path.\n",
    "\n",
    "\n",
    "- max_length=100:\n",
    "\n",
    "This argument sets the maximum length of the generated summary to 100 tokens.\n",
    "The model will continue generating tokens (words) for the summary until it either reaches the specified max_length or generates the end-of-sequence token, whichever comes first.\n",
    "Setting a maximum length helps prevent the model from generating unreasonably long or never-ending summaries.\n",
    "\n",
    "\n",
    "- early_stopping=True:\n",
    "\n",
    "This argument tells the model to stop generating the summary as soon as it produces the end-of-sequence token, even if the generated sequence is shorter than the max_length.\n",
    "End-of-sequence tokens are special tokens that indicate the end of a sequence, similar to a period at the end of a sentence.\n",
    "\n",
    "By setting early_stopping=True, we allow the model to stop generating the summary once it has produced a complete and coherent sequence, without having to generate up to the max_length if it's not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc9c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=100, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69305bb0",
   "metadata": {},
   "source": [
    "Finally, we print the generated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15984a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The Astonishing Hypothesis is a 1994 book by scientist Francis Crick about consciousness and neuroscience. In it, Crick promotes the idea that consciousness is produced by physical and chemical processes in the brain, and that neuroscience will eventually have a theory which can explain consciousness.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2f5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
